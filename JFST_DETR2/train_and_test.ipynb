{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472a18aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Clearing module cache...\n",
      "âœ“ Cache cleared\n",
      "\n",
      "ğŸ“¦ Loading modules from fresh...\n",
      "  âœ“ MaskDataset loaded\n",
      "  âœ“ SEPN modules loaded\n",
      "  âœ“ DY_PS modules loaded\n",
      "  âœ“ Hybrid Encoder modules loaded\n",
      "  âœ“ Hungarian Matcher modules loaded\n",
      "\n",
      "âœ“ Using device: cuda\n",
      "âœ“ All modules imported successfully\n",
      "\n",
      "ğŸ§ª Testing ResNet18Backbone creation...\n",
      "âœ“ ResNet18Backbone created successfully!\n",
      "ğŸ§ª Testing GAAM creation...\n",
      "âœ“ GAAM created successfully!\n",
      "Total images: 1195\n",
      "Train images (80%): 956\n",
      "Val images (20%): 239\n",
      "\n",
      "âœ… Data loading complete!\n"
     ]
    }
   ],
   "source": [
    "# ===== CRITICAL: ëª¨ë“  ìºì‹œ ì´ˆê¸°í™” =====\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "print(\"ğŸ”„ Clearing module cache...\")\n",
    "# í˜„ì¬ ë¡œë“œëœ ëª¨ë“  ëª¨ë“ˆ ì œê±°\n",
    "for module_name in list(sys.modules.keys()):\n",
    "    if any(x in module_name for x in ['SEPN', 'DY_PS', 'MaskDataset', 'hybrid_encoder', 'Hungrian_match']):\n",
    "        print(f\"  Removing: {module_name}\")\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "print(\"âœ“ Cache cleared\")\n",
    "\n",
    "# ===== Core Libraries =====\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€\n",
    "sys.path.insert(0, '/data2/project/2025summer/yjh0913/JSFT_DETR')\n",
    "\n",
    "# ===== PyTorch =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ===== Torchvision =====\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.ops import generalized_box_iou, box_iou\n",
    "\n",
    "# ===== External Modules Import (Fresh Load) =====\n",
    "print(\"\\nğŸ“¦ Loading modules from fresh...\")\n",
    "from MaskDataset import MaskDataset\n",
    "print(\"  âœ“ MaskDataset loaded\")\n",
    "\n",
    "from SEPN import ResNet18Backbone, SEPN\n",
    "print(\"  âœ“ SEPN modules loaded\")\n",
    "\n",
    "from DY_PS import DySample, PSConv\n",
    "print(\"  âœ“ DY_PS modules loaded\")\n",
    "\n",
    "from hybrid_encoder import AIFI, CCFM, HybridEncoderBlock\n",
    "print(\"  âœ“ Hybrid Encoder modules loaded\")\n",
    "\n",
    "from Hungrian_match import (\n",
    "    box_cxcywh_to_xyxy,\n",
    "    HungarianMatcher,\n",
    "    RTDETRDetection,\n",
    "    SetCriterion\n",
    ")\n",
    "print(\"  âœ“ Hungarian Matcher modules loaded\")\n",
    "\n",
    "# ê¸°ë³¸ ì„¤ì •\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nâœ“ Using device: {device}\")\n",
    "print(\"âœ“ All modules imported successfully\\n\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: ResNet18Backbone ìƒì„± ì‹œë„\n",
    "print(\"ğŸ§ª Testing ResNet18Backbone creation...\")\n",
    "try:\n",
    "    test_backbone = ResNet18Backbone()\n",
    "    print(\"âœ“ ResNet18Backbone created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating ResNet18Backbone: {e}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: GAAM ìƒì„± ì‹œë„\n",
    "print(\"ğŸ§ª Testing GAAM creation...\")\n",
    "try:\n",
    "    from SEPN import GAAM\n",
    "    test_gaam = GAAM(256, 128)\n",
    "    print(\"âœ“ GAAM created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating GAAM: {e}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. collate_fn (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)\n",
    "# -----------------------------\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch], dim=0)\n",
    "    targets = [b[1] for b in batch]\n",
    "    return imgs, targets\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘\n",
    "# -----------------------------\n",
    "def get_image_paths(img_dir, exts=(\".jpg\", \".png\", \".jpeg\", \".bmp\")):\n",
    "    return [\n",
    "        os.path.join(img_dir, f)\n",
    "        for f in os.listdir(img_dir)\n",
    "        if f.lower().endswith(exts)\n",
    "    ]\n",
    "\n",
    "\n",
    "img_dir = \"/data2/project/2025summer/yjh0913/DB-1/Images\"      # ë„¤ ì´ë¯¸ì§€ í´ë”\n",
    "mask_dir = \"/data2/project/2025summer/yjh0913/DB-1/Masks\"      # ë„¤ ë§ˆìŠ¤í¬ í´ë”\n",
    "\n",
    "all_img_paths = get_image_paths(img_dir)\n",
    "print(f\"Total images: {len(all_img_paths)}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 8:2 ë¶„í•  (í•˜ì§€ë§Œ trainì—ëŠ” 8ë§Œ ì‚¬ìš©)\n",
    "# -----------------------------\n",
    "random.seed(42)\n",
    "random.shuffle(all_img_paths)\n",
    "\n",
    "split_idx = int(len(all_img_paths) * 0.8)\n",
    "train_img_paths = all_img_paths[:split_idx]\n",
    "val_img_paths   = all_img_paths[split_idx:]   # â† ë§Œë“¤ì–´ë‘ì§€ë§Œ trainì—ëŠ” ì•ˆ ì”€\n",
    "\n",
    "print(f\"Train images (80%): {len(train_img_paths)}\")\n",
    "print(f\"Val images (20%): {len(val_img_paths)}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Train Dataset (8ë§Œ ì‚¬ìš©)\n",
    "# -----------------------------\n",
    "train_dataset = MaskDataset(\n",
    "    img_paths=train_img_paths,\n",
    "    mask_dir=mask_dir,\n",
    "    img_size=640\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Data loading complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28908f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JFSTDETR(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=1,\n",
    "        hidden_dim=256,\n",
    "        num_queries=100\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Backbone\n",
    "        self.backbone = ResNet18Backbone()\n",
    "\n",
    "        # SEPN\n",
    "        self.sepn = SEPN()\n",
    "\n",
    "        # Channel alignment\n",
    "        self.proj3 = nn.Conv2d(128, hidden_dim, 1)\n",
    "        self.proj4 = nn.Conv2d(256, hidden_dim, 1)\n",
    "        self.proj5 = nn.Conv2d(512, hidden_dim, 1)\n",
    "\n",
    "        # DySample (ë™ì  ìƒ˜í”Œë§)\n",
    "        self.refine = DySample(hidden_dim)\n",
    "\n",
    "        # Hybrid Encoder\n",
    "        self.encoder = HybridEncoderBlock(hidden_dim)\n",
    "\n",
    "        # Detection head\n",
    "        self.detector = RTDETRDetection(\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes,\n",
    "            num_queries=num_queries\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone\n",
    "        p2, p3, p4, p5 = self.backbone(x)\n",
    "\n",
    "        # SEPN\n",
    "        p3, p4, p5 = self.sepn(p2, p3, p4, p5)\n",
    "\n",
    "        # Channel align\n",
    "        p3 = self.proj3(p3)\n",
    "        p4 = self.proj4(p4)\n",
    "        p5 = self.proj5(p5)\n",
    "\n",
    "        # DySample (ê° scaleë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ 2ë°° ì—…ìƒ˜í”Œë§)\n",
    "        p3 = self.refine(p3)\n",
    "        p4 = self.refine(p4)\n",
    "        p5 = self.refine(p5)\n",
    "\n",
    "        # Hybrid Encoder\n",
    "        p3, p4, p5 = self.encoder(p3, p4, p5)\n",
    "\n",
    "        # Flatten (RT-DETR ë°©ì‹)\n",
    "        B, C, H3, W3 = p3.shape\n",
    "        mem3 = p3.flatten(2).permute(0, 2, 1)\n",
    "        mem4 = p4.flatten(2).permute(0, 2, 1)\n",
    "        mem5 = p5.flatten(2).permute(0, 2, 1)\n",
    "        memory = torch.cat([mem3, mem4, mem5], dim=1)\n",
    "\n",
    "        # Detection\n",
    "        return self.detector(memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841cf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = JFSTDETR(\n",
    "    num_classes=1,\n",
    "    hidden_dim=256,\n",
    "    num_queries=100\n",
    ").to(device)\n",
    "\n",
    "# Xavier uniform initialization (??? ??)\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "matcher = HungarianMatcher(\n",
    "    cost_class=1,\n",
    "    cost_bbox=5,\n",
    "    cost_giou=2\n",
    ")\n",
    "\n",
    "criterion = SetCriterion(\n",
    "    num_classes=1,\n",
    "    matcher=matcher,\n",
    "    weight_dict={\n",
    "        \"loss_ce\": 1,\n",
    "        \"loss_bbox\": 5,\n",
    "        \"loss_giou\": 2\n",
    "    }\n",
    ")\n",
    "\n",
    "base_lr = 1e-4\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=base_lr,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "warmup_epochs = 3\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20d1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model / DataLoader / Criterion / Optimizer confirmed\n",
      "[Epoch 000] Loss: 0.0000 | CE: nan | BBox: nan | GIoU: nan | Skipped batches: 478 | NaN batches: 478\n",
      "âœ… Saved best model (loss=0.0000)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# ?? ??\n",
    "# -------------------------\n",
    "if 'model' not in globals():\n",
    "    raise NameError(\"? Model not initialized\")\n",
    "\n",
    "if 'train_loader' not in globals():\n",
    "    raise NameError(\"? train_loader not initialized\")\n",
    "\n",
    "if 'criterion' not in globals():\n",
    "    raise NameError(\"? criterion not initialized\")\n",
    "\n",
    "if 'optimizer' not in globals():\n",
    "    raise NameError(\"? optimizer not initialized\")\n",
    "\n",
    "print(\"? Model / DataLoader / Criterion / Optimizer confirmed\")\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "# -------------------------\n",
    "# ?? ??\n",
    "# -------------------------\n",
    "save_dir = \"./checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "num_epochs = 100\n",
    "\n",
    "# =========================\n",
    "# TRAIN LOOP\n",
    "# =========================\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    sum_ce = 0.0\n",
    "    sum_bbox = 0.0\n",
    "    sum_giou = 0.0\n",
    "    nan_count = 0\n",
    "    empty_batches = 0\n",
    "    valid_batches = 0\n",
    "\n",
    "    if epoch < warmup_epochs:\n",
    "        warmup_lr = base_lr * (epoch + 1) / warmup_epochs\n",
    "        for group in optimizer.param_groups:\n",
    "            group[\"lr\"] = warmup_lr\n",
    "\n",
    "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        targets = [\n",
    "            {\n",
    "                \"boxes\": t[\"boxes\"].to(device),\n",
    "                \"labels\": t[\"labels\"].to(device)\n",
    "            }\n",
    "            for t in targets\n",
    "        ]\n",
    "\n",
    "        if sum(t[\"boxes\"].shape[0] for t in targets) == 0:\n",
    "            empty_batches += 1\n",
    "\n",
    "        # -----------------\n",
    "        # forward\n",
    "        # -----------------\n",
    "        outputs = model(imgs)\n",
    "        loss, loss_dict = criterion(outputs, targets)\n",
    "\n",
    "        # NaN / Inf ??\n",
    "        if not torch.isfinite(loss):\n",
    "            nan_count += 1\n",
    "            optimizer.zero_grad()\n",
    "            continue\n",
    "\n",
    "        # -----------------\n",
    "        # backward\n",
    "        # -----------------\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # ?? Transformer ???\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        sum_ce += loss_dict[\"loss_ce\"].item()\n",
    "        sum_bbox += loss_dict[\"loss_bbox\"].item()\n",
    "        sum_giou += loss_dict[\"loss_giou\"].item()\n",
    "        valid_batches += 1\n",
    "\n",
    "    if epoch >= warmup_epochs:\n",
    "        scheduler.step()\n",
    "\n",
    "    # -----------------\n",
    "    # epoch log\n",
    "    # -----------------\n",
    "    denom = max(valid_batches, 1)\n",
    "    avg_loss = total_loss / denom\n",
    "    avg_ce = sum_ce / denom\n",
    "    avg_bbox = sum_bbox / denom\n",
    "    avg_giou = sum_giou / denom\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch:03d}] \"\n",
    "        f\"Loss: {avg_loss:.4f} | \"\n",
    "        f\"CE: {avg_ce:.3f} | \"\n",
    "        f\"BBox: {avg_bbox:.3f} | \"\n",
    "        f\"GIoU: {avg_giou:.3f} | \"\n",
    "        f\"Empty GT batches: {empty_batches} | \"\n",
    "        f\"NaN batches: {nan_count}\"\n",
    "    )\n",
    "\n",
    "    # -----------------\n",
    "    # best model ??\n",
    "    # -----------------\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": best_loss\n",
    "            },\n",
    "            os.path.join(save_dir, \"jfst_detr_best.pth\")\n",
    "        )\n",
    "        print(f\"? Saved best model (loss={best_loss:.4f})\")\n",
    "\n",
    "print(\"\n",
    "\" + \"=\" * 50)\n",
    "print(\"?? Training completed successfully!\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "# ===============================\n",
    "# box utils\n",
    "# ===============================\n",
    "def cxcywh_to_xyxy(boxes):\n",
    "    cx, cy, w, h = boxes.unbind(-1)\n",
    "    return torch.stack([\n",
    "        cx - w / 2,\n",
    "        cy - h / 2,\n",
    "        cx + w / 2,\n",
    "        cy + h / 2\n",
    "    ], dim=-1)\n",
    "\n",
    "# ===============================\n",
    "# postprocess (DETR style)\n",
    "# ===============================\n",
    "def postprocess(pred_logits, pred_boxes, score_thresh=0.5):\n",
    "    probs = F.softmax(pred_logits, dim=-1)\n",
    "    scores, _ = probs[..., :-1].max(dim=-1)  # remove background\n",
    "    keep = scores > score_thresh\n",
    "    return pred_boxes[keep], scores[keep]\n",
    "\n",
    "# ===============================\n",
    "# TP / FP / FN\n",
    "# ===============================\n",
    "def calc_tp_fp_fn(pred_boxes, gt_boxes, iou_thresh=0.5):\n",
    "    if len(pred_boxes) == 0:\n",
    "        return 0, 0, len(gt_boxes)\n",
    "\n",
    "    ious = box_iou(pred_boxes, gt_boxes)\n",
    "    tp = 0\n",
    "    matched = set()\n",
    "\n",
    "    for i in range(len(pred_boxes)):\n",
    "        max_iou, idx = ious[i].max(dim=0)\n",
    "        if max_iou >= iou_thresh and idx.item() not in matched:\n",
    "            tp += 1\n",
    "            matched.add(idx.item())\n",
    "\n",
    "    fp = len(pred_boxes) - tp\n",
    "    fn = len(gt_boxes) - tp\n",
    "    return tp, fp, fn\n",
    "\n",
    "# ===============================\n",
    "# AP (mAP@0.5)\n",
    "# ===============================\n",
    "def compute_ap(recalls, precisions):\n",
    "    recalls = np.concatenate(([0.], recalls, [1.]))\n",
    "    precisions = np.concatenate(([0.], precisions, [0.]))\n",
    "\n",
    "    for i in range(len(precisions) - 1, 0, -1):\n",
    "        precisions[i - 1] = max(precisions[i - 1], precisions[i])\n",
    "\n",
    "    idx = np.where(recalls[1:] != recalls[:-1])[0]\n",
    "    return np.sum((recalls[idx + 1] - recalls[idx]) * precisions[idx + 1])\n",
    "\n",
    "# ===============================\n",
    "# evaluation\n",
    "# ===============================\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device, score_thresh=0.5, iou_thresh=0.5):\n",
    "    model.eval()\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    precisions, recalls = [], []\n",
    "\n",
    "    for imgs, targets in dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        for i in range(len(imgs)):\n",
    "            pb, _ = postprocess(\n",
    "                outputs[\"pred_logits\"][i],\n",
    "                outputs[\"pred_boxes\"][i],\n",
    "                score_thresh\n",
    "            )\n",
    "\n",
    "            gt = targets[i][\"boxes\"]\n",
    "            pb = cxcywh_to_xyxy(pb).cpu()\n",
    "            gt = cxcywh_to_xyxy(gt).cpu()\n",
    "\n",
    "            tp, fp, fn = calc_tp_fp_fn(pb, gt, iou_thresh)\n",
    "\n",
    "            total_tp += tp\n",
    "            total_fp += fp\n",
    "            total_fn += fn\n",
    "\n",
    "            p = tp / (tp + fp + 1e-6)\n",
    "            r = tp / (tp + fn + 1e-6)\n",
    "            precisions.append(p)\n",
    "            recalls.append(r)\n",
    "\n",
    "    precision = total_tp / (total_tp + total_fp + 1e-6)\n",
    "    recall    = total_tp / (total_tp + total_fn + 1e-6)\n",
    "    f1        = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    map50     = compute_ap(np.array(recalls), np.array(precisions))\n",
    "\n",
    "    return precision, recall, f1, map50\n",
    "\n",
    "# ===============================\n",
    "# RUN (í•™ìŠµëœ ëª¨ë¸ë¡œ í‰ê°€)\n",
    "# ===============================\n",
    "print(\"\\nğŸ“Š Evaluation on validation set...\")\n",
    "\n",
    "# val_img_pathsì—ì„œ DataLoader ìƒì„±\n",
    "val_dataset = MaskDataset(\n",
    "    img_paths=val_img_paths,\n",
    "    mask_dir=mask_dir,\n",
    "    img_size=640\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ 1ë¡œ ì„¤ì •\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "\n",
    "# í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš© (ìƒˆë¡œ ë§Œë“¤ì§€ ì•ŠìŒ)\n",
    "precision, recall, f1, map50 = evaluate(\n",
    "    model,  # â† ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ ì¬ì‚¬ìš©\n",
    "    val_loader,\n",
    "    device,\n",
    "    score_thresh=0.5,\n",
    "    iou_thresh=0.5\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“ˆ EVALUATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1-score  : {f1:.4f}\")\n",
    "print(f\"mAP@0.5   : {map50:.4f}\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yjh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}